{
  "task": "compressed_37(middleversion)"     //  classical image sr for x2/x3/x4. root/task/images-models-options
  , "model": "plain" // "plain" | "plain2" if two inputs
  , "gpu_ids": [5]
  , "dist": true

  , "scale": 1       // 2 | 3 | 4
  , "n_channels": 3  // broadcast to "datasets", 1 for grayscale, 3 for color

  , "path": {
    "root": "compressed"            // "denoising" | "superresolution" | "dejpeg"
    , "pretrained_netG": null      // path of pretrained model. We fine-tune X3/X4 models from X2 model, so that `G_optimizer_lr` and `G_scheduler_milestones` can be halved to save time.
    , "pretrained_netE": null      // path of pretrained model
  }

  , "datasets": {
    "train": {
      "name": "train_dataset"           // just name
      , "dataset_type": "nnpf16"         // "nnpf" | "dncnn" | "dnpatch" | "fdncnn" | "ffdnet" | "sr" | "srmd" | "dpsr" | "plain" | "plainpatch" | "jpeg"
      , "dataroot_H": "trainsets/PNG_train/png_qp00"         // path of H training dataset. DIV2K (800 training images)
      , "dataroot_L": "trainsets/PNG_train/png_qp37"              // path of L training dataset

      , "H_size": 128                   // 96/144|192/384 | 128/192/256/512. LR patch size is set to 48 or 64 when compared with RCAN or RRDB.

      , "dataloader_shuffle": true
      , "dataloader_num_workers": 16
      , "dataloader_batch_size": 8      // batch size 1 | 16 | 32 | 48 | 64 | 128. Total batch size =4x8=32 in SwinIR
    }
    , "test": {
      "name": "test_dataset"            // just name
      , "dataset_type": "nnpf16"         // "dncnn" | "dnpatch" | "fdncnn" | "ffdnet" | "sr" | "srmd" | "dpsr" | "plain" | "plainpatch" | "jpeg"
      , "dataroot_H": "testsets/PNG_test/QP00"  // path of H testing dataset
      , "dataroot_L": "testsets/PNG_test/QP37"              // path of L testing dataset

    }
  }

  , "netG": {
    "net_type": "PROPOSED_abl4_remove_mfb_reverse_9x9",
    "upscale": 1,
    "in_chans": 3,
    "n_feats": 80,
    "LayerNorm_type": "WithBias",
    "drop_path_rate": 0.3,
    "layer_scale_init_value": 1e-06,
    "num_heads": 8,
    "ffn_expansion_factor": 3.0,
    "init_type": "default",
    "scale": 1
  }

  , "train": {
    "G_lossfn_type": "charbonnier"               // "l1" preferred | "l2sum" | "l2" | "ssim" | "charbonnier"
    , "G_lossfn_weight": 0.7            // default
    , "G_charbonnier_eps": 1e-9

    , "hf_loss": true   // hf loss 추가
    
    , "E_decay": 0.999                  // Exponential Moving Average for netG: set 0 to disable; default setting 0.999

    , "G_optimizer_type": "adam"        // fixed, adam is enough
    , "G_optimizer_lr": 4e-4            // learning rate
    , "G_optimizer_wd": 0               // weight decay, default 0
    , "G_optimizer_clipgrad": null      // unused
    , "G_optimizer_reuse": true         //

    , "G_scheduler_type": "MultiStepLR" // "MultiStepLR" is enough
    , "G_scheduler_milestones": [250000, 400000, 450000, 475000, 500000]
    , "G_scheduler_gamma": 0.5
    // , "G_scheduler_type": "CosineAnnealing" 
    // , "G_scheduler_T_max" : 500000
    // , "G_scheduler_eta_min" : 1e-6 

    , "G_regularizer_orthstep": null    // unused
    , "G_regularizer_clipstep": null    // unused

    , "G_param_strict": true
    , "E_param_strict": true

    , "checkpoint_test": 5000           // for testing
    , "checkpoint_save": 5000           // for saving model
    , "checkpoint_print": 200           // for print

  // , "train": {
  //   "G_lossfn_type": "charbonnier"               // "l1" preferred | "l2sum" | "l2" | "ssim" | "charbonnier"
  //   , "G_lossfn_weight": 0.65            // default : 1.0
  //   , "G_charbonnier_eps": 1e-9


  //   , "hf_loss": true   // hf loss 추가

  //   , "E_decay": 0.999                  // Exponential Moving Average for netG: set 0 to disable; default setting 0.999

  //   , "G_optimizer_type": "adam"        // fixed, adam is enough
  //   , "G_optimizer_lr": 2e-4            // learning rate
  //   , "G_optimizer_wd": 0               // weight decay, default 0
  //   , "G_optimizer_clipgrad": null      // unused
  //   , "G_optimizer_reuse": true         //

  //   , "G_scheduler_type": "MultiStepLR" // "MultiStepLR" is enough
  //   , "G_scheduler_milestones": [250000, 400000, 450000, 475000, 500000]
  //   , "G_scheduler_gamma": 0.5

  //   , "G_regularizer_orthstep": null    // unused
  //   , "G_regularizer_clipstep": null    // unused

  //   , "G_param_strict": true
  //   , "E_param_strict": true

  //   , "checkpoint_test": 5000           // for testing
  //   , "checkpoint_save": 5000           // for saving model
  //   , "checkpoint_print": 200           // for print
  }
}
